{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d5cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be02fe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# event types\n",
    "# ET_EDIT = 'File.Edit'\n",
    "# ET_KEY = 'X-Keystroke'\n",
    "# edit types\n",
    "INSERT = 'Insert'\n",
    "DELETE = 'Delete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bf296f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entry:\n",
    "    # change_text is the text to be inserted or deleted\n",
    "    # row_idx is the index of the row in the dataframe that contains the change\n",
    "    # text_index is the index in the string in InsertText or DeleteText column where the change_text is found\n",
    "    # insert is a boolean: true if insert, false if delete\n",
    "    def __init__(self, change_text, row_idx, text_index, insert, deleted_insert_idx=-1):\n",
    "        self.change_text = change_text\n",
    "        self.row_idx = row_idx\n",
    "        self.text_index = text_index\n",
    "        self.insert = insert\n",
    "        self.deleted_insert_idx = deleted_insert_idx\n",
    "        \n",
    "    def __str__(self):\n",
    "        return 'text: {}, row_idx: {}, text_index: {}, insert: {}'.format(self.change_text, self.row_idx, self.text_index, self.insert)\n",
    "    \n",
    "    def isInsert(self):\n",
    "        return self.insert\n",
    "        \n",
    "    def isDelete(self):\n",
    "        return not self.insert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd38ef47",
   "metadata": {},
   "source": [
    "## Reconstruct the final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73cbc803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_diff(row):\n",
    "    l = 0\n",
    "    if row.InsertText == row.InsertText:\n",
    "        l = len(row.InsertText)\n",
    "    if row.DeleteText == row.DeleteText:\n",
    "        l -= len(row.DeleteText)\n",
    "    return l\n",
    "\n",
    "def reconstruct(df, debug=False):\n",
    "    # find the number of characters added or subtracted at each step\n",
    "    charsAdded = df.apply(char_diff, axis=1)\n",
    "    max_size = charsAdded.cumsum().max()\n",
    "    # Allocate buffers\n",
    "    inserts = []\n",
    "    deletes = []\n",
    "    deleted_inserts = []\n",
    "    buf = '' # the end file\n",
    "    delete_buf = '' # characters that were deleted\n",
    "\n",
    "    # Create an error data frame holding rows that failed\n",
    "    error = pd.DataFrame(columns=df.columns)\n",
    "    error['XError'] = 0\n",
    "    # Build the file. Iterate over each row of the data frame.\n",
    "    for row_idx,row in df[df.EventType == 'File.Edit'].iterrows():\n",
    "#     for row_idx,row in df.iterrows():\n",
    "        code_idx = int(row.SourceLocation)\n",
    "#         code_idx = -1\n",
    "#         if not np.isnan(row.SourceLocation):\n",
    "#             code_idx = int(row.SourceLocation)\n",
    "        if row.DeleteText and row.DeleteText == row.DeleteText:\n",
    "            di_len = len(deleted_inserts)\n",
    "            deleted_inserts = deleted_inserts + inserts[code_idx:code_idx+len(row.DeleteText)]\n",
    "            \n",
    "#             # Use what's in the buffer because what's in DeleteText may not match\n",
    "            deleted_text = buf[code_idx:code_idx+len(row.DeleteText)]\n",
    "            if (len(deleted_text) != len(row.DeleteText)):\n",
    "#                 raise Exception(f'deleted_text != row.DeleteText: {len(deleted_text)} {len(row.DeleteText)}')\n",
    "                print(f'Warning: len(deleted_text) != len(row.DeleteText): {len(deleted_text)} {len(row.DeleteText)} at index {code_idx}')\n",
    "            \n",
    "            inserts = inserts[:code_idx] + inserts[code_idx+len(row.DeleteText):]\n",
    "            buf = buf[:code_idx] + buf[code_idx+len(row.DeleteText):]\n",
    "            local_deletes = [Entry(row.DeleteText[k], row_idx, k, False, deleted_insert_idx=di_len+k) for k in range(len(row.DeleteText))]\n",
    "            deletes = local_deletes + deletes\n",
    "            delete_buf = row.DeleteText + delete_buf\n",
    "\n",
    "#             inserts = inserts[:code_idx] + inserts[code_idx+len(deleted_text):]\n",
    "#             buf = buf[:code_idx] + buf[code_idx+len(deleted_text):]\n",
    "#             local_deletes = [Entry(deleted_text, row_idx, k, False, deleted_insert_idx=di_len+k) for k in range(len(row.DeleteText))]\n",
    "#             deletes = local_deletes + deletes\n",
    "#             delete_buf = deleted_text + delete_buf\n",
    "        if row.InsertText and row.InsertText == row.InsertText:\n",
    "            local_inserts = [Entry(row.InsertText[k], row_idx, k, True) for k in range(len(row.InsertText))]\n",
    "            inserts = inserts[:code_idx] + local_inserts + inserts[code_idx:]\n",
    "            buf = buf[:code_idx] + row.InsertText + buf[code_idx:]\n",
    "        else:\n",
    "            error = error.append(row)\n",
    "            error.iloc[0, error.columns.get_loc('XError')] = 'Unsupported edit type'\n",
    "    if debug:\n",
    "        print('Errors:')\n",
    "        display(error)\n",
    "\n",
    "    return buf, delete_buf, inserts, deletes, deleted_inserts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b167ed9d",
   "metadata": {},
   "source": [
    "## Look between timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea573a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data-2019/bak/project-events.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89000fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "test = df[df.user_id == 100036].copy()\n",
    "test = test[(test.timestamp > 1548976440848)&(test.timestamp < 1548976584332)]\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77c7913",
   "metadata": {},
   "source": [
    "## Create a regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e0ba673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Lilliputian|Lilliputian John|John|Lilliputian|illiputia|lliputi|liput|a#?[ ]{0,3}[0-9]{8}\n",
      "['John Lilliputian', 'John', 'lliputi', 'a12345678', 'a#35354646', 'A# 87658765', 'a 56565656', 'a  34563456']\n",
      "['Stoic Stu', 'a12341234', 'rambulat']\n",
      "['Stoic Stu', 'a12341234']\n"
     ]
    }
   ],
   "source": [
    "# Version used for fall 2021 data\n",
    "from itertools import permutations, combinations\n",
    "\n",
    "# Returns a regular expression to match and mask.\n",
    "# subjectID - the name of the student with each of first, last, etc separated by a space\n",
    "# include_Anum - whether to include a regular expression to match Aggie A#\n",
    "def subjectID2mask_re_2021(subjectID, include_Anum=True, substrings=True):\n",
    "    res = []\n",
    "    \n",
    "    # Get \"First Last\" and \"Last First\"\n",
    "    id_parts = subjectID.split() # Probably just first and last name but could include a middle initial\n",
    "    for i in range(len(id_parts), 0, -1):\n",
    "        for comb in combinations(id_parts, i):\n",
    "            perms = permutations(comb)\n",
    "            for perm in perms:\n",
    "                r = ' '.join(perm)\n",
    "                if len(r) > 1:\n",
    "                    res = res + [r]\n",
    "\n",
    "    # Find larger substrings of each name. For example, if the name is Christensen, this will add\n",
    "    # hristense, ristens, and isten. The reason for this is if the name somehow is only partial\n",
    "    # in the keystrokes. For example, the student might have missed typing the last character.\n",
    "    # In our working example, this would result in Christense. In this case, we would match\n",
    "    # hristense and the masked keys would result in C@@@@@@@@@. Ideally we would attempt matches\n",
    "    # on every substring, but there are n(n+1)/2 of those -- way too many. There are a linear\n",
    "    # number of substrings using our scheme and it strikes a balance between performance and\n",
    "    # quality of masking/deidentification.\n",
    "    if substrings:\n",
    "        for name in id_parts:\n",
    "            res = res + [name[i:-i] for i in range(1,int(len(name)/2)-1)]\n",
    "\n",
    "    # Add a RE for A#\n",
    "    if include_Anum:\n",
    "        res = res + ['a#?[ ]{0,3}[0-9]{8}']\n",
    "    return '|'.join(res)\n",
    "\n",
    "r = subjectID2mask_re_2021('John Lilliputian')\n",
    "print(r)\n",
    "print([m[0] for m in re.finditer(r, 'John Lilliputian John illiputi a12345678 a#35354646 A# 87658765 a 56565656 a  34563456  a    97597531', flags=re.IGNORECASE)])\n",
    "r = subjectID2mask_re_2021('Alomarian Stoic Parambulator Stu')\n",
    "print([m[0] for m in re.finditer(r, 'Stoic Stu\\na12341234 parambulat', flags=re.IGNORECASE)])\n",
    "\n",
    "r = subjectID2mask_re_2021('Alomarian Stoic Parambulator Stu', substrings=False)\n",
    "print([m[0] for m in re.finditer(r, 'Stoic Stu\\na12341234 parambulat', flags=re.IGNORECASE)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ddf80a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Lilliputian|John L|John|Lilliputian|John|Andy|Andrew|Brim|Chad|Mano|Mono|a#?[ ]{0,3}[0-9]{8}\n",
      "John M. Edwards|John Edwards|John|Edwards|John|Edwards|Andy|Andrew|Brim|Chad|Mano|Mono|a#?[ ]{0,3}[0-9]{8}\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations, combinations\n",
    "\n",
    "# Returns a regular expression to match and mask.\n",
    "# names - names for the student\n",
    "# include_Anum - whether to include a regular expression to match Aggie A#\n",
    "def subjectID2mask_re_2019(names, include_Anum=True, substrings=True):\n",
    "    res = names.copy()\n",
    "    \n",
    "    for name in names:\n",
    "        for n in name.split():\n",
    "            n = n.strip()\n",
    "            if len(n) > 1 and n[1] != '.':\n",
    "                res.append(n)\n",
    "                \n",
    "    res = res + ['Andy','Andrew','Brim','Chad','Mano','Mono']\n",
    "\n",
    "    # Add a RE for A#\n",
    "    if include_Anum:\n",
    "        res = res + ['a#?[ ]{0,3}[0-9]{8}']\n",
    "    return '|'.join(res)\n",
    "\n",
    "r = subjectID2mask_re_2019(['John Lilliputian', 'John L'])\n",
    "print(r)\n",
    "r = subjectID2mask_re_2019(['John M. Edwards', 'John Edwards'])\n",
    "print(r)\n",
    "# print([m[0] for m in re.finditer(r, 'John Lilliputian John illiputi a12345678 a#35354646 A# 87658765 a 56565656 a  34563456  a    97597531', flags=re.IGNORECASE)])\n",
    "# r = subjectID2mask_re_2019('Alomarian Stoic Parambulator Stu')\n",
    "# print([m[0] for m in re.finditer(r, 'Stoic Stu\\na12341234 parambulat', flags=re.IGNORECASE)])\n",
    "\n",
    "# r = subjectID2mask_re_2019('Alomarian Stoic Parambulator Stu', substrings=False)\n",
    "# print([m[0] for m in re.finditer(r, 'Stoic Stu\\na12341234 parambulat', flags=re.IGNORECASE)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79798ce0",
   "metadata": {},
   "source": [
    "## Mask a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12cef94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_WITH = '@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@'\n",
    "def mask_char_in_insert_text(df, row_idx, text_index, replacement_char):\n",
    "    insert_col_idx = df.columns.get_loc('InsertText')\n",
    "    s = df.iloc[row_idx].InsertText\n",
    "    char_to_replace = s[text_index]\n",
    "    df.iloc[row_idx,insert_col_idx] = s[:text_index] + replacement_char + s[text_index+1:]\n",
    "    \n",
    "    # Look nearby (within two rows) for a keystroke and mask it as well\n",
    "    arr = np.intersect1d(df.index[(df.EventType == 'X-Keystroke')&\n",
    "                                  (df.InsertText == char_to_replace)],\n",
    "                         pd.RangeIndex(row_idx-2, row_idx+3))\n",
    "    df.iloc[arr,insert_col_idx] = replacement_char\n",
    "    \n",
    "# Returns the masked dataframe and all strings that were masked\n",
    "def mask(df, program, entries, is_insert, text_to_replace, replace_with=REPLACE_WITH, deleted_inserts = None, in_place = False):\n",
    "#     display(df)\n",
    "    masked_strings = set()\n",
    "    insert_col_idx = df.columns.get_loc('InsertText')\n",
    "    delete_col_idx = df.columns.get_loc('DeleteText')\n",
    "    if in_place:\n",
    "        masked = df\n",
    "    else:\n",
    "        masked = df.copy()\n",
    "\n",
    "    for it in re.finditer(text_to_replace, program, flags=re.IGNORECASE):\n",
    "        start_i = it.start()\n",
    "        text_to_replace = it[0]\n",
    "        masked_strings.add(text_to_replace)\n",
    "\n",
    "        # Iterate through each character of the input text\n",
    "        for i in range(len(text_to_replace)):\n",
    "            replacement_char = replace_with[i]\n",
    "            char_to_replace = text_to_replace[i]\n",
    "            entry = entries[start_i+i] # entry with data on the character we are about to mask\n",
    "            if entry.change_text != char_to_replace:\n",
    "                print('ERROR: change_text not equal to char_to_replace: {}, {}', entry, char_to_replace)\n",
    "            row_idx = entry.row_idx\n",
    "            text_index = entry.text_index\n",
    "            if (is_insert != entry.insert):\n",
    "                print('Error: {} is not equal to insert = {}'.format(entry, is_insert))\n",
    "            \n",
    "            if entry.insert:\n",
    "                mask_char_in_insert_text(masked, row_idx, text_index, replacement_char)\n",
    "            else:\n",
    "                # Deletion\n",
    "                # Mask the DeleteText string\n",
    "                s = masked.iloc[row_idx].DeleteText\n",
    "                masked.iloc[row_idx,delete_col_idx] = s[:text_index] + replacement_char + s[text_index+1:]\n",
    "                # Mask the InsertText string where the text was originally inserted\n",
    "                di = deleted_inserts[entry.deleted_insert_idx]\n",
    "#                 s = masked.iloc[di.row_idx].InsertText\n",
    "#                 if s[di.text_index] != char_to_replace:\n",
    "#                     print('ERROR: s[di.text_index] != char_to_replace: {}, {}, {}', s, di, char_to_replace)\n",
    "#                     print('  {}, {}'.format(row_idx, di.row_idx))\n",
    "#                     print('  {}'.format(masked.iloc[di.row_idx]))\n",
    "                mask_char_in_insert_text(masked, di.row_idx, di.text_index, replacement_char)\n",
    "            \n",
    "\n",
    "    return masked, masked_strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab1caa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_df(df, mask_re, replace_with=REPLACE_WITH):\n",
    "    df = df.copy().reset_index()\n",
    "    program, deleted_text, entries, deletes, deleted_inserts = reconstruct(df)\n",
    "\n",
    "    masked = df.copy()\n",
    "    masked, ms1 = mask(masked, program, entries, True, mask_re, replace_with)\n",
    "    masked, ms2 = mask(masked, deleted_text, deletes, False, mask_re, replace_with, deleted_inserts)\n",
    "\n",
    "    return masked, ms1.union(ms2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989cfbba",
   "metadata": {},
   "source": [
    "## Test reconstruct and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213dbb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/deident.csv')#, header=None)\n",
    "# df = showyourwork2progsnap2('showyourwork.log', 'John Edwards', 'Assign1')\n",
    "df = pd.read_csv('test.ps2')\n",
    "subjectID = df.SubjectID.unique()[0]\n",
    "display(df['CodeStateSection'].unique())\n",
    "df = df[(df.SubjectID == subjectID)&(df['CodeStateSection'] == 'task1.py')]\n",
    "# display(df)\n",
    "\n",
    "print(reconstruct(df)[0])\n",
    "\n",
    "print('\\n\\n******* Masking ********\\n')\n",
    "\n",
    "masked, masked_strings = mask_df(df, subjectID2mask_re(subjectID))\n",
    "program, deleted_text,_,_,_ = reconstruct(masked)\n",
    "print(f'Masked strings: {masked_strings}')\n",
    "print(program)\n",
    "print('\\n\\n** Deleted **\\n' + deleted_text)\n",
    "print('\\n\\n** Inserts **\\n', ''.join(masked[(masked.EventType == 'File.Edit')&(masked.EditType == INSERT)].InsertText))\n",
    "print('\\n\\n** Keystrokes **\\n', ''.join(masked.loc[masked.EventType == 'X-Keystroke', 'X-Metadata']))\n",
    "\n",
    "# temp = pd.concat([df,masked]).drop_duplicates(keep=False)\n",
    "# display(temp[temp.EventID < 100].head(40))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98317dac",
   "metadata": {},
   "source": [
    "## Add a number to each character in an ascii string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b07f6790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane Rasmussen - Assign12 - task2.py\n"
     ]
    }
   ],
   "source": [
    "def add_to_ascii(s, add):\n",
    "    ch = [c+add for c in bytes(s, 'utf-8')]\n",
    "    return ''.join([str(chr(c)) for c in ch])\n",
    "\n",
    "s = 'Ebof!Sbtnvttfo!.!Bttjho23!.!ubtl3/qz'\n",
    "print(add_to_ascii(s, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a20dde6",
   "metadata": {},
   "source": [
    "# Deidentify all students in ps2 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "070c3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns (df, submission, deleted) where\n",
    "#  df - the deidentified data frame\n",
    "#  submission - the reconstructed submission code\n",
    "#  deleted - all deleted characters in reverse order\n",
    "def deidentifyps2(df_all, id2names=None, header_offset=1):\n",
    "    df_result = []\n",
    "    all_masked_strings = set()\n",
    "    programs = ''\n",
    "    program_heads = ''\n",
    "    deleted = ''\n",
    "    \n",
    "    df_all = df_all[df_all['CodeStateSection'].str.slice(-3) == '.py'].copy()\n",
    "    df_all['uniqueID'] = df_all.SubjectID + df_all.AssignmentID + df_all['CodeStateSection']\n",
    "    for ID in df_all.uniqueID.unique():\n",
    "        masked = df_all[df_all.uniqueID == ID].copy().reset_index()\n",
    "        \n",
    "        f = masked.iloc[0]\n",
    "        id_string = f'{f.SubjectID} - {f.AssignmentID} - {f[\"CodeStateSection\"]}'\n",
    "        print(id_string)\n",
    "        \n",
    "        try:\n",
    "            # Do not sort if deidentifying ShowYourWork.\n",
    "            masked.sort_values('ClientTimestamp', inplace=True)\n",
    "            if not id2names:\n",
    "                # fall 2021\n",
    "                mask_re = subjectID2mask_re_2021(f.SubjectID)\n",
    "            else:\n",
    "                # 2019\n",
    "                mask_re = subjectID2mask_re_2019(list(id2names[f.SubjectID]))\n",
    "\n",
    "            masked,masked_strings = mask_df(masked, mask_re)\n",
    "            if (len(masked_strings) > 0):\n",
    "                all_masked_strings = all_masked_strings.union(masked_strings)\n",
    "                print(f'  Masked strings: {masked_strings}')\n",
    "\n",
    "            program, deleted_text,_,_,_ = reconstruct(masked)\n",
    "            program_header = f'\\n\\n____{add_to_ascii(id_string, header_offset)}****\\n'\n",
    "            if len(program.strip()) > 0:\n",
    "                programs = programs+program_header+program\n",
    "            lines = program.split('\\n')\n",
    "            num_lines = 3 if len(lines)>3 else len(lines)\n",
    "            lines = lines[:num_lines]\n",
    "            lines = '\\n'.join(lines)\n",
    "            if len(lines.strip()) > 0:\n",
    "                program_heads = program_heads+program_header+lines\n",
    "                \n",
    "            if len(deleted_text.strip()) > 0:\n",
    "                deleted = deleted+program_header+deleted_text\n",
    "\n",
    "            df_result.append(masked)\n",
    "#             if df_result is None:\n",
    "#                 df_result = masked\n",
    "#             else:\n",
    "#                 df_result = pd.concat([df_result, masked])\n",
    "        except Exception as e:\n",
    "            print(f'Failed to mask {id_string}: {str(e)}')\n",
    "            traceback.print_exc()\n",
    "\n",
    "    return pd.concat(df_result), all_masked_strings, programs, program_heads, deleted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1436798f",
   "metadata": {},
   "source": [
    "# Deidentify 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f60ee76",
   "metadata": {},
   "source": [
    "## Read a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4e2d02e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwards/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py:3251: DtypeWarning: Columns (10,11,12,13,35) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_2019 = pd.read_csv('data-2019/phanon2ps2-6.csv')\n",
    "df_2019.SubjectID = df_2019.SubjectID.astype('str')\n",
    "df_2019.AssignmentID = df_2019.AssignmentID.astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182429a5",
   "metadata": {},
   "source": [
    "## Do the deidentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40f9cae1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100007 - 128 - tasks.py\n",
      "100007 - 130 - tasks.py\n",
      "100007 - 132 - tasks.py\n",
      "100007 - 134 - tasks.py\n",
      "100007 - 136 - tasks.py\n",
      "Masked 42.5549 seconds\n",
      "Masked strings: set()\n"
     ]
    }
   ],
   "source": [
    "students = list(df_2019.SubjectID.unique())\n",
    "# students = set(students[:8])\n",
    "students = ['100007']#, '100003', '100030', '100036', '100072', '100073']\n",
    "# print('Deidentifying {}'.format(students))\n",
    "df = df_2019[df_2019.SubjectID.isin(set(students))].copy()\n",
    "df = df.drop(['index'], axis=1, errors='ignore')\n",
    "# display(df.head())\n",
    "\n",
    "# remove invalid source location events\n",
    "bad_mask = ((df.InsertText.isna())&(df.DeleteText.isna()))|~(df.SourceLocation.isna())\n",
    "df = df[bad_mask]\n",
    "\n",
    "# display(df.head())\n",
    "\n",
    "dfs = []\n",
    "n = 20\n",
    "for i in range(0,len(students),n):\n",
    "    tic = time.perf_counter()\n",
    "    # 20 students at a time\n",
    "    df_slice = df[df.SubjectID.isin(students[i:i+n])]\n",
    "    df_masked,ms,programs,program_heads,deleted = deidentifyps2(df_slice, id2names=id2names, header_offset=0)\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Masked {toc - tic:0.4f} seconds\")\n",
    "\n",
    "    print(f'Masked strings: {ms}')\n",
    "\n",
    "    with open(f'data-2019/run4/deidentified-programs{i}.txt', 'w') as f:\n",
    "        f.write(programs)\n",
    "    with open(f'data-2019/run4/deidentified-program-heads{i}.txt', 'w') as f:\n",
    "        f.write(program_heads)\n",
    "    with open(f'data-2019/run4/deidentified-deleted{i}.txt', 'w') as f:\n",
    "        f.write(deleted)\n",
    "    if not df_masked is None:\n",
    "        df_masked = df_masked.drop(['level_0','uniqueID','index'], axis=1)\n",
    "        dfs.append(df_masked)\n",
    "\n",
    "# pd.concat(dfs).to_csv('data-2019/phanon2ps2-3.csv', index=False)\n",
    "pd.concat(dfs).to_csv('../website/KeystrokePlayback/test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ead35b",
   "metadata": {},
   "source": [
    "## Deidentify a single assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50013ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\n",
    "    ('____100176 - 130 - tasks.py****','montgoomery'),\n",
    "    ('____100380 - 132 - tasks.py****','zhenngxi'),\n",
    "    ('____100481 - 200 - tasks.py****','harmom'),\n",
    "    ('____100130 - 136 - tasks.py****','grvuer')\n",
    "]\n",
    "\n",
    "df_rest = df_2019.copy()\n",
    "print(len(df_2019))\n",
    "to_add = []\n",
    "for header,search in problems:\n",
    "    print(header,search)\n",
    "\n",
    "    df_to_mask, df_rest = split_df_from_header(df_rest, header, return_rest=True)\n",
    "    df_to_mask = df_to_mask.copy()\n",
    "    student = header[4:10]\n",
    "    id2names[student] = [search]\n",
    "\n",
    "    df_masked,ms,programs,program_heads,deleted = deidentifyps2(df_to_mask, id2names=id2names, header_offset=0)\n",
    "    \n",
    "    to_add.append(df_masked)\n",
    "\n",
    "    # pd.concat(dfs).to_csv('data-2019/phanon2ps2-3.csv', index=False)\n",
    "    # pd.concat(dfs).to_csv('../website/KeystrokePlayback/test.csv', index=False)\n",
    "    df_masked.to_csv('../website/KeystrokePlayback/test.csv', index=False)\n",
    "\n",
    "new_df = pd.concat(to_add+[df_rest])\n",
    "print(len(new_df))\n",
    "# new_df.to_csv('data-2019/phanon2ps2-5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd67e79d",
   "metadata": {},
   "source": [
    "## Construct id2names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac760d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ''\n",
    "with open('data-2019/id2name.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "id2names = {}\n",
    "joined = ''.join(lines)\n",
    "arr = ['100'+s for s in joined.split('100')][1:]\n",
    "for entry in arr:\n",
    "    earr = entry.split('\\n')\n",
    "    subjectID = earr[0].split()[0].strip()\n",
    "    entries = set([])\n",
    "    for line in earr[1:]:\n",
    "        line = line.strip()\n",
    "        if len(line)>0:\n",
    "            entries.add(line)\n",
    "    id2names[subjectID] = entries\n",
    "\n",
    "for key in id2names.keys():\n",
    "    print(key)\n",
    "    for val in id2names[key]:\n",
    "        print(f'  {val}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1273c029",
   "metadata": {},
   "source": [
    "## Retrofit Phanon code_added/code_removed fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "96e21155",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_2019.copy()\n",
    "df.code_added = df.InsertText\n",
    "df.code_removed = df.DeleteText\n",
    "\n",
    "df.to_csv('data-2019/phanon2ps2-6.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6d3225",
   "metadata": {},
   "source": [
    "## Retrofit to Phanon format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "92a93f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019.columns\n",
    "df_phanon = df_2019[['user_id', 'project_id', 'task',\n",
    "       'change_type', 'code_added', 'code_removed', 'timestamp', 'input',\n",
    "       'output', 'has_error', 'user_terminated', 'startLine', 'startCol',\n",
    "       'endLine', 'endCol', 'operation', 'key']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d704fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data-2019/phanon-keystrokes.csv')\n",
    "# df.head()\n",
    "\n",
    "df_phanon.sort_values(['user_id','project_id','timestamp'], inplace=True)\n",
    "df_phanon.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5a000ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phanon.to_csv('data-2019/phanon-keystrokes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8883d05f",
   "metadata": {},
   "source": [
    "## Remove problem submissions\n",
    "Look at each user and see if there are any names in inserted or deleted code, then remove in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc233b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_2019#[df_2019.SubjectID.isin([str(n) for n in range(100000,100100)])]\n",
    "\n",
    "students = list(temp.SubjectID.unique())\n",
    "masks = [subjectID2mask_re_2019(list(id2names[student])) for student in students]\n",
    "\n",
    "# ifound = df[~(df.InsertText.isna())&(df.InsertText.str.contains(mask_re, flags=re.IGNORECASE))]\n",
    "# dfound = df[~(df.DeleteText.isna())&(df.DeleteText.str.contains(mask_re, flags=re.IGNORECASE))]\n",
    "\n",
    "for student in students:\n",
    "    df = temp[temp.SubjectID == student]\n",
    "    mask_re = subjectID2mask_re_2019(list(id2names[student]))\n",
    "    ifound = df[~(df.InsertText.isna())&(df.InsertText.str.contains(mask_re, flags=re.IGNORECASE))]\n",
    "    dfound = df[~(df.DeleteText.isna())&(df.DeleteText.str.contains(mask_re, flags=re.IGNORECASE))]\n",
    "    if len(ifound) > 0:\n",
    "        print('insert', student, len(ifound), ifound.AssignmentID.values, mask_re)\n",
    "#         display(ifound)\n",
    "    if len(dfound) > 0:\n",
    "        print('delete', student, len(dfound), ifound.AssignmentID.values, mask_re)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7540aa",
   "metadata": {},
   "source": [
    "These are submissions where an identifying string somehow ended up in the InsertText or DeleteText. If this happens, remove the entire submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c0f7aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = set(['100007130','100068132','100084204','100087204','100116129','100183204','100206195','100208132','100212138','100241132','100287200','100326204','100336133','100387136','100393133','100404129','100416132','100417130','100417132','100418133','100425204','100427132','100435128','100435136','100444138','100452130','100461204','100482195','100507204','100511138'])\n",
    "df_2019[~((df_2019.SubjectID.astype('str')+df_2019.AssignmentID.astype('str')).isin(to_remove))].to_csv('data-2019/phanon2ps2-3.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1d7b4092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['128', '130', '134', '136'], dtype=object)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2019[(df_2019.SubjectID == '100068')].AssignmentID.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90c1301",
   "metadata": {},
   "source": [
    "## Write a single user to test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3d0d8891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the dataframe matching the header and the dataframe not matching the header\n",
    "def split_df_from_header(df, header, return_rest=False):\n",
    "    s = header\n",
    "    s = s[4:]\n",
    "    s = s.split()\n",
    "    student = s[0]\n",
    "    assignment = s[2]\n",
    "    masked = (df.SubjectID == student)&(df.AssignmentID == assignment)\n",
    "    if return_rest:\n",
    "        return df[masked], df[~masked]\n",
    "    return df[masked], None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ac9d66eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2019[df_2019.SubjectID.isin([str(n) for n in range(100007,100008)])].to_csv('../website/KeystrokePlayback/test.csv', index=False)\n",
    "\n",
    "# problems = [\n",
    "#     ('____100176 - 130 - tasks.py****','montgoomery'),\n",
    "#     ('____100380 - 132 - tasks.py****','zhenngxi'),\n",
    "#     ('____100481 - 200 - tasks.py****','harmom'),\n",
    "#     ('____100130 - 136 - tasks.py****','grvuer')\n",
    "# ]\n",
    "\n",
    "header = '____100103 - 207 - tasks.py****'\n",
    "split_df_from_header(df_2019, header)[0].to_csv('../website/KeystrokePlayback/test.csv', index=False)\n",
    "# s = s[4:]\n",
    "# s = s.split()\n",
    "# student = s[0]\n",
    "# assignment = s[2]\n",
    "# df_2019[(df_2019.SubjectID == student)&(df_2019.AssignmentID == assignment)]\n",
    "\n",
    "# for i in range(100015, 100550, 5):\n",
    "#     df_2019[df_2019.SubjectID.isin([str(n) for n in range(i,i+5)])].to_csv(f'../website/KeystrokePlayback/test{i}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a209c272",
   "metadata": {},
   "source": [
    "# To fix\n",
    "\n",
    "\n",
    "# Done\n",
    "* 100176 - 130 - montgoomery\n",
    "* 100380 - 132 - zhenngxi\n",
    "* 100481 - 200 - harmom\n",
    "* 100130 - 136 - grvuer\n",
    "* 100007 130 Erin Griffin edit 4745, 5513 -- just delete the participant?\n",
    "* setValue can have nan source location: test.loc[(test.EventType == 'File.Edit')&(test.SourceLocation.isna()), 'SourceLocation'] = 0\n",
    "* 100003 Garnder\n",
    "* 100030 O'Loughlin\n",
    "* 100036 Jake Miller\n",
    "* 100034 Mary Chidester\n",
    "* 100108 - 132 - task1.py -- \"i am will\"\n",
    "* 100108 - 136 - task0.py -- will perfect\n",
    "* 100184 - 128 - task0.py -- jimmy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14166fd1",
   "metadata": {},
   "source": [
    "## Take out common words and symbols from \"check\" files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9d19ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 'data-2019/run3'\n",
    "# file = 'heads'\n",
    "file = 'programs'\n",
    "# file = 'deleted'\n",
    "\n",
    "with open(run+'/aaa-masked-strings.txt') as f:\n",
    "    text = f.read()\n",
    "masked = set([s.strip(\"' \\n\").lower() for s in text.split(',')])\n",
    "\n",
    "# Words that we will pull out of the check text\n",
    "# with open('words-no-names.txt') as f:\n",
    "with open('wordsbig.txt') as f:\n",
    "    lines = f.readlines()\n",
    "words = set([w.strip() for w in lines])\n",
    "\n",
    "# The file to reduce\n",
    "with open(run+'/'+file+'.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Don't pull out any words that we masked\n",
    "words = words - set(masked)\n",
    "words = words - set(['http', 'zoom'])\n",
    "\n",
    "# Add some common words to pull out\n",
    "words = words.union(set(['pendown','penup','fillcolor','setheading','phanon']))\n",
    "\n",
    "header2body = {}\n",
    "for line in lines:\n",
    "    if line[:7] == '____100':\n",
    "        header = line.strip()\n",
    "        header2body[header] = set()\n",
    "    else:\n",
    "        keep = [w.lower().strip() for w in re.split('[^a-zA-Z]', line)]\n",
    "        keep = [w for w in keep if len(w)>0 and w not in words]\n",
    "        for i in re.finditer('[0-9]{5}', line):\n",
    "            keep.append(i[0])\n",
    "        if len(keep)>0:\n",
    "            header2body[header] = header2body[header].union(set(keep))\n",
    "\n",
    "s = ''\n",
    "for header, body in header2body.items():\n",
    "    if len(body) > 0:\n",
    "        s = s + '\\n\\n' + header + '\\n' + ' '.join(body)\n",
    "\n",
    "with open(run+'/'+file+'-min.txt', 'w') as f:\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ff56289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns\n",
    "df2 = df2[['native_index', 'user_id', 'project_id', 'task',\n",
    "       'change_type', 'code_added', 'code_removed', 'timestamp', 'input',\n",
    "       'output', 'has_error', 'user_terminated', 'startLine', 'startCol',\n",
    "       'endLine', 'endCol', 'operation', 'key', 'elapsed', 'change_index',\n",
    "       'ID', 'ID_no_task', 'SubjectID', 'EventID', 'AssignmentID',\n",
    "       'CodeStateSection', 'EventType', 'InsertText', 'DeleteText',\n",
    "       'SourceLocation', 'ClientTimestamp', 'EditType']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
